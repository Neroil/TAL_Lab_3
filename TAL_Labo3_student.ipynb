{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://heig-vd.ch/docs/default-source/doc-global-newsletter/2020-slim.svg\" alt=\"HEIG-VD Logo\" width=\"100\" align=\"right\" /> \n",
    "\n",
    "# Cours TAL - Laboratoire 3<br/>*Depedency parser* pour le français dans spaCy\n",
    "\n",
    "**Objectif**\n",
    "\n",
    "Évaluer l'analyseur syntaxique en dépendances fourni par spaCy dans le modèle `fr_core_news_sm`, puis le comparer avec un analyseur entraîné par vous-mêmes.  Les données sont les mêmes qu'au Labo 2 et la démarche du labo est similaire aussi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prise en main de l'analyseur de spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_sm\") # charge la pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1a.** Pour la pipeline `fr_core_news_sm`, veuillez afficher les traitements disponibles, puis désactiver tous les traitements sauf `tok2vec`, `morphologizer` et `parser`, puis vérifiez que la désactivation a bien fonctionné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitements disponibles : ['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "Traitements activés : ['tok2vec', 'morphologizer', 'parser']\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "print(\"Traitements disponibles :\", nlp.pipe_names)\n",
    "for pipe in nlp.pipe_names:\n",
    "    if pipe not in {\"tok2vec\", \"morphologizer\",\"parser\"}:\n",
    "        nlp.disable_pipe(pipe)\n",
    "\n",
    "print(\"Traitements activés :\", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.fr.examples import sentences\n",
    "s1 = sentences[2] # prenons la 3e phrase comme exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1b.** Veuillez analyser `s1` avec la pipeline `nlp` puis afficher chaque token, son POS tag, et son étiquette indiquant la relation de dépendance (entre crochets, après le token).  Quelle information essentielle manque dans cette représentation ?\n",
    "\n",
    "Note : le *morphologizer* fournit aussi les POS tags.  La liste des tags possibles est [fournie par spaCy](https://spacy.io/models/fr#fr_core_news_md-labels).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "San Francisco envisage d'interdire les robots coursiers sur les trottoirs\n",
      "San [PRON, nsubj, head: envisage]\n",
      "Francisco [PROPN, flat:name, head: San]\n",
      "envisage [VERB, ROOT, head: envisage]\n",
      "d' [ADP, case, head: interdire]\n",
      "interdire [NOUN, obl:arg, head: envisage]\n",
      "les [DET, det, head: robots]\n",
      "robots [NOUN, obj, head: envisage]\n",
      "coursiers [ADJ, amod, head: robots]\n",
      "sur [ADP, case, head: trottoirs]\n",
      "les [DET, det, head: trottoirs]\n",
      "trottoirs [NOUN, nmod, head: robots]\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code et votre réponse ici.\n",
    "doc = nlp(s1)\n",
    "print(doc.text)\n",
    "for token in doc:\n",
    "    print(f\"{token.text} [{token.pos_}, {token.dep_}, head: {token.head.text}]\")\n",
    "\n",
    "\n",
    "# Il manquait le head dans le code précédent. Pourquoi c'est important ? Car il permet de savoir quel est le mot qui gouverne le mot courant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c.** Veuillez afficher tous les groupes de mots qui sont soit des `nsubj` soit des `obj` dans la phrase `s1` (c'est à dire les sujets et les objets du verbe).   Indication : le sous-arbre d'un token *t* est accessible comme `t.subtree`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsubj : San [PRON, nsubj, head: envisage]\n",
      "\tSan [PRON, nsubj, head: envisage]\n",
      "\tFrancisco [PROPN, flat:name, head: San]\n",
      "obj : robots [NOUN, obj, head: envisage]\n",
      "\tles [DET, det, head: robots]\n",
      "\trobots [NOUN, obj, head: envisage]\n",
      "\tcoursiers [ADJ, amod, head: robots]\n",
      "\tsur [ADP, case, head: trottoirs]\n",
      "\tles [DET, det, head: trottoirs]\n",
      "\ttrottoirs [NOUN, nmod, head: robots]\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "for token in doc:\n",
    "    if token.dep_ in [\"nsubj\", \"obj\"]:\n",
    "        print(f\"{token.dep_} : {token.text} [{token.pos_}, {token.dep_}, head: {token.head.text}]\")\n",
    "        for t in token.subtree:\n",
    "            print(f\"\\t{t.text} [{t.pos_}, {t.dep_}, head: {t.head.text}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Évaluation quantitative de l'analyseur sur une phrase \n",
    "\n",
    "Les données sont les mêmes que celles du Labo 2.  Vous les avez déjà transformées au Labo 2 dans un format utilisable par spaCy, dans un dossier nommé `Labo2/spacy_data` que vous allez réutiliser.  Les trois fichiers contiennent des phrases en français annotées aussi avec les arbres de dépendance.  Le fichier `fr-ud-train.conllu` est destiné à l'entraînement, `fr-ud-dev.conllu` au réglage des paramètres, et `fr-ud-test.conllu` à l'évaluation finale.\n",
    "\n",
    "**2a.** En inspectant un des fichiers d'origine avec un éditeur texte, veuillez indiquer dans quelles colonnes se trouvent les informations sur les relations de dépendance, et comment elles sont représentées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez écrire votre réponse dans cette cellule.\n",
    "# La colonne 7 donne l’identifiant du mot auquel le mot courant est rattaché (le \"gouverneur\"), ou 0 si c’est le mot racine.\n",
    "# La colonne 8 indique le type de relation de dépendance (comme sujet, objet, etc.).\n",
    "# La colonne 9 peut contenir des dépendances supplémentaires sous forme de paires (gouverneur, relation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin, Doc\n",
    "test_data = DocBin().from_disk(\"spacy_data/fr-ud-test.spacy\")\n",
    "# for doc in test_data.get_docs(nlp.vocab):  # exemple\n",
    "#     for sent in doc.sents:\n",
    "#         print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b**. On rapplle que les données des fichiers convertis peuvent être chargées dans un objet de type `DocBin`.  Ici, un tel objet contient un ensemble de documents, chacun contenant 10 phrases.  Chaque document est un objet de type `Doc`.  Le code donné ci-dessous vous permet de charger les données de test et vous montre comment les afficher.\n",
    "\n",
    "* Veuillez stocker la *7e phrase du 2e document des données de test* dans une variable nommée `s2`.\n",
    "* Veuillez afficher cette phrase (elle commence par \"Trois ans\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase : Trois ans plus tard, il tient un discours sur la crise.\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "sents = list(test_data.get_docs(nlp.vocab))\n",
    "s2 = list(sents[1].sents)[6]\n",
    "\n",
    "print(f\"Phrase : {s2.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c.** En utilisant `displaCy` comme expliqué [ici](https://spacy.io/usage/visualizers) veuillez afficher graphiquement l'arbre de dépendances de la phrase `s2` tel qu'il est fourni dans les données.  Pour être affichée, la phrase doit être transformée en objet `Doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"105b80baeb7e4abca64956b65fa3695e-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Trois</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">ans</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">plus</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">tard,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">il</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">tient</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">un</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">discours</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">sur</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">crise.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-105b80baeb7e4abca64956b65fa3695e-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-105b80baeb7e4abca64956b65fa3695e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-105b80baeb7e4abca64956b65fa3695e-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 925.0,2.0 925.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-105b80baeb7e4abca64956b65fa3695e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-105b80baeb7e4abca64956b65fa3695e-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-105b80baeb7e4abca64956b65fa3695e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-105b80baeb7e4abca64956b65fa3695e-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-105b80baeb7e4abca64956b65fa3695e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,266.5 L578.0,254.5 562.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-105b80baeb7e4abca64956b65fa3695e-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-105b80baeb7e4abca64956b65fa3695e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-105b80baeb7e4abca64956b65fa3695e-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-105b80baeb7e4abca64956b65fa3695e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-105b80baeb7e4abca64956b65fa3695e-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-105b80baeb7e4abca64956b65fa3695e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-105b80baeb7e4abca64956b65fa3695e-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-105b80baeb7e4abca64956b65fa3695e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-105b80baeb7e4abca64956b65fa3695e-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-105b80baeb7e4abca64956b65fa3695e-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-105b80baeb7e4abca64956b65fa3695e-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-105b80baeb7e4abca64956b65fa3695e-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML('<span class=\"tex2jax_ignore\">{}</span>'.format(\n",
    "    displacy.render(s2, style=\"dep\", jupyter=False)\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d.** En utilisant `displaCy`, veuillez également afficher l'arbre de dépendances calculé par la pipeline `nlp` pour cette même phrase `s2`.  Pour être analysée et affichée, la phrase doit être transformée en objet `Doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"16f68956db0141ddb3ad70a4fbcf2af2-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Trois</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">ans</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">plus</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">tard,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">il</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">tient</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">un</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">discours</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">sur</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">crise.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,177.0 390.0,177.0 390.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:mod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-5\" stroke-width=\"2px\" d=\"M1120,264.5 C1120,177.0 1265.0,177.0 1265.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,266.5 L1112,254.5 1128,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-16f68956db0141ddb3ad70a4fbcf2af2-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "doc2 = nlp(s2.as_doc())\n",
    "display(HTML('<span class=\"tex2jax_ignore\">{}</span>'.format(\n",
    "    displacy.render(doc2, style=\"dep\", jupyter=False)\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2e.** Veuillez comparer les deux arbres de dépendances et indiquer ici les différences.  Quel est le taux de correction de la pipeline `nlp` sur cette phrase ?\n",
    "\n",
    "Suggestion : il peut être utile de sauvegarder les deux arbres dans des images SVG, en écrivant dans un fichier le résultat retourné par `displacy.render` avec l'option `jupyter = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taux de correction : 84.62%\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre réponse ici.\n",
    "with open(\"original_tree.svg\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(displacy.render(s2, style=\"dep\", jupyter=False))\n",
    "    \n",
    "with open(\"predicted_tree.svg\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(displacy.render(doc2, style=\"dep\", jupyter=False))\n",
    "\n",
    "# On peut voir que la différence se trouve dans le groupe \"ans plus tard il tient\"\n",
    "# L'arbre original analyse correctement \"il\" comme sujet de \"tient\", qui est la racine de la phrase.\n",
    "# Dans l'arbre prédit, \"il\" est incorrectement rattaché à \"tard\", et \"tient\" n'est plus la racine.\n",
    "# Cela fausse toute la structure sujet-verbe et la relation temporelle \"ans plus tard\".\n",
    "\n",
    "original_tokens = [(token.text, token.dep_, token.head.text) for token in s2]\n",
    "predicted_tokens = [(token.text, token.dep_, token.head.text) for token in doc2]\n",
    "\n",
    "# Calculer le taux de correction\n",
    "correct = sum(1 for g, p in zip(original_tokens, predicted_tokens) if g == p)\n",
    "total = len(original_tokens)\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"Taux de correction : {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2f.**  Veuillez appliquer le `Scorer` de spaCy (voir Labo 2) et afficher les deux scores qu'il produit pour l'analyse en dépendances (avec trois décimales après la virgule).  Retrouvez-vous les scores de la question précédente ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.scorer import Scorer\n",
    "from spacy.training import Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAS : 0.818\n",
      "LAS : 0.818\n",
      "\n",
      "Comparaison avec le calcul manuel précédent:\n",
      "Taux de correction calculé manuellement: 0.846\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code et votre réponse ici.\n",
    "scorer = Scorer()\n",
    "\n",
    "scores = scorer.score([Example(nlp(s2.as_doc()), s2.as_doc())])\n",
    "\n",
    "print(f\"UAS : {scores['dep_uas']:.3f}\")\n",
    "print(f\"LAS : {scores['dep_las']:.3f}\")\n",
    "\n",
    "# Comparer avec le calcul manuel précédent\n",
    "print(f\"\\nComparaison avec le calcul manuel précédent:\")\n",
    "# 0.846\n",
    "print(f\"Taux de correction calculé manuellement: {accuracy:.3f}\")\n",
    "\n",
    "# On trouve en effet un score différent.\n",
    "# Le score obtenu avec `scorer.score()` est plus rigoureux car il s'appuie sur l'identifiant du mot gouverneur (head) (et pas juste son texte)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Évaluation du *dependency parser* de `fr_core_news_sm` sur l'ensemble des phrases test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3a.** Veuillez calculer les deux scores qui caractérisent l'analyseur en dépendances de la pipeline `nlp` sur toutes les données de test présentes dans `test_data`.  Comment se comparent ces scores avec ceux mentionnés [dans la documentation de fr_core_news_sm](https://spacy.io/models/fr#fr_core_news_sm) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAS : 0.760\n",
      "LAS : 0.619\n",
      "\n",
      "Comparaison avec les scores de la documentation:\n",
      "Documentation fr_core_news_sm: UAS = 88%, LAS = 84%\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "examples = []\n",
    "# Parcourir tous les documents et phrases dans les données de test\n",
    "for doc in test_data.get_docs(nlp.vocab):\n",
    "    for sent in doc.sents:\n",
    "        \n",
    "        parsed_sent = nlp(sent.text)\n",
    "        example = Example(sent.as_doc(), parsed_sent)\n",
    "        examples.append(example)\n",
    "\n",
    "scores = scorer.score(examples)\n",
    "\n",
    "\n",
    "print(f\"UAS : {scores['dep_uas']:.3f}\")\n",
    "print(f\"LAS : {scores['dep_las']:.3f}\")\n",
    "\n",
    "print(\"Documentation fr_core_news_sm: UAS = 88%, LAS = 84%\")\n",
    "\n",
    "# On voit qu'ils sont bien moins bon...\n",
    "\n",
    "# Le score UAS (0.760) reste assez proche de celui de la documentation (88 %) (tout est relatif ...), \n",
    "# ce qui montre que les dépendances sont globalement bien trouvées, même s’il y a un peu plus d’erreurs. \n",
    "# Cela peut venir du fait que le modèle a été entraîné sur un autre type de texte. Le découpage du texte en plusieurs parties a peut-être aussi fait perdre du contexte.\n",
    "\n",
    "# Le score LAS (0.619), lui, est bien plus bas que celui de la documentation (84 %). \n",
    "# Cela montre que le modèle a plus de mal à bien choisir le type de relation entre les mots, surtout si le contexte manque ou si les phrases sont difficiles à analyser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b.** Le *scorer* fournit également des scores détaillés pour chaque type de relation de dépendances.  Veuillez afficher ces valeurs dans un tableau proprement formaté, trié par score F1 décroissant, avec trois décimales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Relation  Precision  Recall  F1-Score\n",
      "         det      0.770   0.928     0.842\n",
      "        case      0.775   0.854     0.813\n",
      "          cc      0.794   0.797     0.795\n",
      "  nsubj:pass      0.860   0.683     0.761\n",
      "        mark      0.779   0.723     0.750\n",
      "    aux:pass      0.925   0.628     0.748\n",
      "         cop      0.741   0.720     0.730\n",
      "       nsubj      0.676   0.757     0.714\n",
      "      nummod      0.664   0.750     0.705\n",
      "        root      0.795   0.617     0.695\n",
      "      advmod      0.700   0.678     0.689\n",
      "         obj      0.694   0.684     0.689\n",
      "        amod      0.743   0.588     0.656\n",
      "   flat:name      0.632   0.610     0.621\n",
      "        nmod      0.594   0.539     0.565\n",
      "       xcomp      0.613   0.489     0.544\n",
      "   acl:relcl      0.547   0.500     0.522\n",
      "       fixed      0.337   0.523     0.410\n",
      "         acl      0.416   0.403     0.409\n",
      "        iobj      0.560   0.318     0.406\n",
      "       advcl      0.382   0.402     0.392\n",
      "       ccomp      0.317   0.465     0.377\n",
      "        conj      0.370   0.381     0.375\n",
      "       appos      0.265   0.437     0.330\n",
      "   parataxis      0.031   0.048     0.038\n",
      "   aux:tense      0.000   0.000     0.000\n",
      "         dep      0.000   0.000     0.000\n",
      "     obl:arg      0.000   0.000     0.000\n",
      "         obl      0.000   0.000     0.000\n",
      "   obl:agent      0.000   0.000     0.000\n",
      "     obl:mod      0.000   0.000     0.000\n",
      "         aux      0.000   0.000     0.000\n",
      "   expl:subj      0.000   0.000     0.000\n",
      "   expl:comp      0.000   0.000     0.000\n",
      "        expl      0.000   0.000     0.000\n",
      "   obj:agent      0.000   0.000     0.000\n",
      "    aux:caus      0.000   0.000     0.000\n",
      "  nsubj:caus      0.000   0.000     0.000\n",
      "    compound      0.000   0.000     0.000\n",
      "   expl:pass      0.000   0.000     0.000\n",
      "  iobj:agent      0.000   0.000     0.000\n",
      "   discourse      0.000   0.000     0.000\n",
      "flat:foreign      0.000   0.000     0.000\n",
      "    vocative      0.000   0.000     0.000\n",
      "       csubj      0.000   0.000     0.000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores_per_type = scores[\"dep_las_per_type\"]\n",
    "df = pd.DataFrame.from_dict(scores_per_type, orient=\"index\")\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = [\"Relation\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "df = df.sort_values(by=\"F1-Score\", ascending=False)\n",
    "df = df.round(3)\n",
    "print(df.to_string(index=False))\n",
    "df_before = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entraîner puis évaluer un nouveau *parser* français dans spaCy\n",
    "\n",
    "Le but de cette partie est d'entraîner une pipeline spaCy pour le français sur les données de `fr-ud-train.conllu`, puis de comparer le modèle obtenu avec le modèle prêt-à-l'emploi testé au point précédent (voir le Labo 2 et les [instructions de spaCy](https://spacy.io/usage/training#quickstart)).\n",
    "\n",
    "**4a.** Paramétrage de l'entraînement :\n",
    "* générez un fichier de départ grâce à [l'interface web](https://spacy.io/usage/training#quickstart), en indiquant que vous gardez seulement les composants `morphologizer` et `parser` dans la pipeline ;\n",
    "* sauvegardez le code généré par spaCy dans un fichier local `base_config.cfg` ;\n",
    "* générez un fichier `config.cfg` sur votre ordinateur en exécutant la ligne de commande suivante. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veuillez effectuer l'entraînement avec la ligne de commande suivante.  Faites plusieurs essais, d'abord avec un petit nombre d'époques (*à indiquer dans config.cfg*), pour estimer le temps nécessaire et observer les messages affichés.  Augmentez progressivement le nombre d'époques, jusqu'à ce que les scores sur le jeu de validation n'augmentent plus (si vous avez le temps).  Pendant combien d'époques entraînez-vous au final ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-09 19:00:07,525] [DEBUG] Config overrides from CLI: ['paths.train', 'paths.dev']\n",
      "\u001b[38;5;4mℹ Saving to output directory: myDEPparser1\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2025-04-09 19:00:12,583] [INFO] Set up nlp object from config\n",
      "[2025-04-09 19:00:12,603] [DEBUG] Loading corpus from path: spacy_data/fr-ud-dev.spacy\n",
      "[2025-04-09 19:00:12,605] [DEBUG] Loading corpus from path: spacy_data/fr-ud-train.spacy\n",
      "[2025-04-09 19:00:12,605] [INFO] Pipeline: ['tok2vec', 'parser', 'morphologizer']\n",
      "[2025-04-09 19:00:12,610] [INFO] Created vocabulary\n",
      "[2025-04-09 19:00:12,611] [INFO] Finished initializing nlp object\n",
      "[2025-04-09 19:01:03,477] [INFO] Initialized pipeline components: ['tok2vec', 'parser', 'morphologizer']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[2025-04-09 19:01:03,497] [DEBUG] Loading corpus from path: spacy_data/fr-ud-dev.spacy\n",
      "[2025-04-09 19:01:03,500] [DEBUG] Loading corpus from path: spacy_data/fr-ud-train.spacy\n",
      "[2025-04-09 19:01:03,503] [DEBUG] Removed existing output directory: myDEPparser1/model-best\n",
      "[2025-04-09 19:01:03,505] [DEBUG] Removed existing output directory: myDEPparser1/model-last\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'parser', 'morphologizer']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS PARSER  LOSS MORPH...  DEP_UAS  DEP_LAS  SENTS_F  POS_ACC  MORPH_ACC  SCORE \n",
      "---  ------  ------------  -----------  -------------  -------  -------  -------  -------  ---------  ------\n",
      "  0       0          0.00       504.38         224.53    24.62     9.44     0.15    34.04      29.37    0.24\n",
      "  0     200       4130.32     37487.07       19241.19    70.76    62.81    73.99    87.24      82.66    0.76\n",
      "  0     400       6120.50     25718.63        9656.62    76.87    70.31    92.07    90.41      87.96    0.81\n",
      "  0     600       6123.18     22255.04        7290.95    78.94    73.42    93.59    91.18      89.35    0.83\n",
      "  0     800       6586.73     21907.81        6618.60    80.20    75.14    90.93    91.83      90.40    0.84\n",
      "  0    1000       6430.06     19704.84        5604.21    80.78    75.87    93.59    92.08      91.06    0.85\n",
      "  0    1200       6636.62     18963.13        5324.76    81.70    76.78    95.20    92.35      91.54    0.86\n",
      "  0    1400       7076.75     19135.38        4978.14    81.57    76.50    93.43    92.68      91.77    0.86\n",
      "  1    1600       6776.56     17540.37        4326.94    82.21    77.51    93.99    92.87      92.23    0.86\n",
      "  1    1800       7159.30     16913.54        4005.13    82.51    78.20    93.82    92.93      92.21    0.86\n",
      "  1    2000       7463.09     16949.62        4111.75    82.67    78.27    95.63    92.90      92.32    0.87\n",
      "  1    2200       7833.71     16875.62        3871.73    82.68    78.42    95.84    93.08      92.49    0.87\n",
      "  1    2400       7976.30     16765.18        4046.38    83.39    79.27    95.56    93.18      92.51    0.87\n",
      "  1    2600       8350.53     17261.07        4008.23    83.27    79.26    95.27    93.06      92.51    0.87\n",
      "  1    2800       8648.91     16998.60        4023.74    83.61    79.51    95.70    93.23      92.76    0.87\n",
      "  2    3000       8848.57     16451.90        3788.27    83.57    79.56    95.40    93.34      92.79    0.87\n",
      "  2    3200       8366.61     14788.35        3164.71    83.58    79.36    95.98    93.29      92.80    0.87\n",
      "  2    3400       9193.85     15511.76        3395.12    83.78    80.00    95.73    93.30      92.77    0.87\n",
      "  2    3600       9622.16     15461.48        3467.72    84.04    80.24    95.99    93.39      92.91    0.88\n",
      "  2    3800       9572.93     15023.80        3273.52    84.00    80.01    95.60    93.43      92.80    0.88\n",
      "  2    4000       9820.76     14826.49        3114.24    84.36    80.46    95.57    93.37      92.98    0.88\n",
      "  2    4200      10038.22     15116.72        3217.39    84.10    80.06    95.31    93.41      92.98    0.88\n",
      "  3    4400       9847.45     14723.89        3180.66    84.39    80.69    96.12    93.44      93.05    0.88\n",
      "  3    4600      10454.58     14290.80        2930.75    84.48    80.74    95.63    93.34      92.92    0.88\n",
      "  3    4800      10535.39     13851.87        2845.77    83.94    80.06    96.02    93.31      92.97    0.88\n",
      "  3    5000      11285.93     14177.00        2909.01    84.09    80.41    95.96    93.44      93.15    0.88\n",
      "  3    5200      11533.12     14300.71        2838.48    84.39    80.55    95.66    93.44      93.11    0.88\n",
      "  3    5400      11378.97     14001.14        2798.33    84.43    80.86    95.41    93.46      93.05    0.88\n",
      "  3    5600      11433.11     13815.98        2978.77    84.47    80.59    95.65    93.51      93.13    0.88\n",
      "  3    5800      12096.00     14077.69        2949.10    84.72    80.73    95.95    93.55      93.18    0.88\n",
      "  4    6000      11708.52     12991.52        2484.54    85.13    81.45    96.20    93.57      93.14    0.88\n",
      "  4    6200      12843.19     13098.56        2636.55    84.96    81.21    95.95    93.54      93.09    0.88\n",
      "  4    6400      12728.02     12939.11        2547.90    85.23    81.42    95.94    93.45      93.10    0.88\n",
      "  4    6600      13955.65     13745.77        2689.04    84.67    81.12    96.29    93.51      93.10    0.88\n",
      "  4    6800      13663.81     13202.39        2583.13    85.02    81.27    95.81    93.44      93.12    0.88\n",
      "  4    7000      13912.33     13447.13        2710.91    84.68    81.11    96.45    93.52      93.23    0.88\n",
      "  4    7200      13974.06     13242.61        2565.99    84.84    81.30    96.56    93.62      93.15    0.88\n",
      "  5    7400      14185.02     12982.01        2565.00    85.20    81.74    95.99    93.56      93.20    0.88\n",
      "  5    7600      14539.60     12306.57        2301.39    85.23    81.78    96.05    93.55      93.16    0.88\n",
      "  5    7800      15813.07     12529.14        2387.88    85.02    81.55    96.16    93.61      93.16    0.88\n",
      "  5    8000      16127.32     12808.65        2437.70    84.91    81.46    96.42    93.62      93.26    0.88\n",
      "  5    8200      16555.84     13072.59        2465.49    85.26    81.86    96.15    93.65      93.24    0.89\n",
      "  5    8400      16081.48     12441.10        2470.22    85.15    81.75    95.84    93.67      93.30    0.88\n",
      "  5    8600      15394.46     12023.58        2360.99    85.05    81.59    96.42    93.67      93.26    0.88\n",
      "  6    8800      16476.69     12609.50        2227.10    85.05    81.64    96.12    93.72      93.26    0.88\n",
      "  6    9000      16600.87     11406.85        2157.20    85.51    82.16    96.43    93.68      93.30    0.89\n",
      "  6    9200      17854.57     11797.56        2275.98    85.09    81.69    96.26    93.69      93.22    0.88\n",
      "  6    9400      17905.57     11762.93        2229.25    85.04    81.64    95.99    93.63      93.23    0.88\n",
      "  6    9600      18257.75     11928.77        2212.81    85.11    81.75    96.36    93.67      93.23    0.88\n",
      "  6    9800      19132.29     12254.84        2345.03    85.56    81.99    96.26    93.63      93.22    0.89\n",
      "  6   10000      19388.44     12267.82        2439.27    85.55    82.07    95.86    93.62      93.22    0.89\n",
      "  7   10200      18898.72     11723.13        2303.14    85.13    81.80    96.26    93.70      93.30    0.88\n",
      "  7   10400      17969.79     10902.95        1937.52    84.83    81.46    96.34    93.64      93.30    0.88\n",
      "  7   10600      20082.55     11236.62        2164.19    85.11    81.53    95.86    93.67      93.24    0.88\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "myDEPparser1/model-last\n"
     ]
    }
   ],
   "source": [
    "# Note : il vaut mieux exécuter cela directement dans une fenêtre de commande, pour voir les logs en temps réel.\n",
    "!python -m spacy train config.cfg \\\n",
    "  --output ./myDEPparser1 \\\n",
    "  --paths.train ./spacy_data/fr-ud-train.spacy \\\n",
    "  --paths.dev ./spacy_data/fr-ud-dev.spacy \\\n",
    "  --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veuillez indiquer ici le nombre d'époques final. \n",
    "# L'entraînement du modèle s’est déroulé sur 7 époques complètes. On observe que les scores sur le jeu de validation (notamment DEP_UAS et DEP_LAS) ont progressivement augmenté jusqu’à environ la 5ᵉ ou 6ᵉ époque, puis se sont stabilisés.\n",
    "# Cela indique que le modèle a atteint un plateau de performance, et que prolonger l’entraînement au-delà de 7 époques n’aurait probablement pas apporté d’amélioration significative.\n",
    "\n",
    "# En analysant la progression du F1-score global (SCORE), on constate qu’il augmente régulièrement durant les premières époques, passant de 0.24 à 0.81.\n",
    "# En se basant uniquement sur cette métrique, on peut conclure que l’amélioration significative s’arrête vers l’époque 2. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4b.**  Veuillez charger le meilleur modèle (pipeline) dans la variable `nlp2` et afficher ses scores sur les données de test.  Comment se comparent les résultats avec les précédents ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAS: 0.880\n",
      "LAS: 0.838\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "\n",
    "nlp2 = spacy.load(\"./myDEPparser1/model-best\")\n",
    "data_test = DocBin().from_disk(\"spacy_data/fr-ud-test.spacy\")\n",
    "\n",
    "scorer = Scorer().score([\n",
    "    Example(\n",
    "        nlp2(Doc(nlp2.vocab, [token.text for token in doc])),\n",
    "        doc\n",
    "    ) for doc in test_data.get_docs(nlp2.vocab)\n",
    "])\n",
    "\n",
    "print(f\"UAS: {scorer['dep_uas']:.3f}\")\n",
    "print(f\"LAS: {scorer['dep_las']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4c.** Veuillez afficher les scores détaillés pour chaque type de relation de dépendances, dans un tableau formaté comme au 3b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Relation  Precision  Recall  F1-Score\n",
      "       det      0.972   0.985     0.978\n",
      "      case      0.921   0.967     0.943\n",
      "  aux:caus      1.000   0.846     0.917\n",
      "       aux      0.915   0.909     0.912\n",
      "    nummod      0.889   0.877     0.883\n",
      "      amod      0.869   0.894     0.881\n",
      "       obj      0.876   0.883     0.879\n",
      "        cc      0.876   0.880     0.878\n",
      "      root      0.875   0.861     0.868\n",
      "     nsubj      0.848   0.881     0.864\n",
      "      mark      0.865   0.861     0.863\n",
      "       cop      0.862   0.856     0.859\n",
      " flat:name      0.829   0.857     0.843\n",
      "     xcomp      0.817   0.802     0.810\n",
      "  aux:pass      0.754   0.868     0.807\n",
      "      nmod      0.805   0.783     0.794\n",
      "    advmod      0.778   0.782     0.780\n",
      "nsubj:caus      1.000   0.600     0.750\n",
      " obj:agent      1.000   0.571     0.727\n",
      "       obl      0.699   0.740     0.719\n",
      "nsubj:pass      0.756   0.680     0.716\n",
      " acl:relcl      0.694   0.667     0.680\n",
      "     ccomp      0.632   0.683     0.656\n",
      "      conj      0.582   0.634     0.607\n",
      "     advcl      0.571   0.627     0.598\n",
      "       acl      0.615   0.571     0.593\n",
      "      expl      0.683   0.500     0.577\n",
      "     fixed      0.900   0.411     0.565\n",
      "      iobj      0.444   0.640     0.525\n",
      "     appos      0.465   0.508     0.486\n",
      "  compound      0.600   0.136     0.222\n",
      " parataxis      0.250   0.094     0.136\n",
      "       dep      0.000   0.000     0.000\n",
      "iobj:agent      0.000   0.000     0.000\n",
      " obl:agent      0.000   0.000     0.000\n",
      " discourse      0.000   0.000     0.000\n",
      "     csubj      0.000   0.000     0.000\n"
     ]
    }
   ],
   "source": [
    "# Veuillez écrire votre code ici.\n",
    "scores_per_type = scorer[\"dep_las_per_type\"]\n",
    "df = pd.DataFrame.from_dict(scores_per_type, orient=\"index\")\n",
    "df.reset_index(inplace=True)\n",
    "df.columns = [\"Relation\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
    "df = df.sort_values(by=\"F1-Score\", ascending=False)\n",
    "df = df.round(3)\n",
    "print(df.to_string(index=False))\n",
    "df_after = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de F1-score à 0 avant entraînement : 20\n",
      "Nombre de F1-score à 0 après entraînement : 5\n"
     ]
    }
   ],
   "source": [
    "# Compter le nombre de F1-scores à 0 pour chaque DataFrame\n",
    "def count_zero_f1(df):\n",
    "    return (df[\"F1-Score\"] == 0.0).sum()\n",
    "\n",
    "f1_zeros_before = count_zero_f1(df_before)  # df_before = tableau AVANT entraînement\n",
    "f1_zeros_after = count_zero_f1(df_after)    # df_after = tableau APRÈS entraînement\n",
    "\n",
    "print(f\"Nombre de F1-score à 0 avant entraînement : {f1_zeros_before}\")\n",
    "print(f\"Nombre de F1-score à 0 après entraînement : {f1_zeros_after}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4d.** Quels changements observez-vous en haut (3 premiers labels) et en bas du classement ?  Voyez-vous un label pour lequel les scores n'augmentent pas avec le parser entraîné ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dans les résultats obtenus, on remarque qu’un certain nombre de relations de dépendances conservent un score F1 nul, même après l'entraînement du parser. \n",
    "# Afin de quantifier cette observation, on compte le nombre de labels avec un F1-score égal à 0 avant et après entraînement. \n",
    "# Cette comparaison nous permet de voir qu'avant il y avait 20 labels avec un F1-score nul, et après il n'y en a plus que 5.\n",
    "\n",
    "# Concernant les 3 relations les moins bien reconnues, avant entraînement, il s’agissait de discourse, flat:foreign, et vocative (toutes avec un F1 = 0.000), ce qui indique une absence totale de reconnaissance.\n",
    "# Avant l'entraînement du parser, les 3 relations de dépendance les mieux reconnues étaient det (F1 = 0.842), case (F1 = 0.813) et cc (F1 = 0.795). Ces labels sont fréquents et relativement simples à identifier, ce qui explique leurs bons scores initiaux. \n",
    "# Après entraînement, on observe une amélioration générale avec en tête aux:caus (F1 = 0.917), det (F1 = 0.978) et case (F1 = 0.943). Cela montre que le modèle a su mieux reconnaître certaines relations, notamment aux:caus qui passe à la 3e place.\n",
    "# Après entraînement, ces mêmes labels restent en bas du classement, avec toujours un F1-score nul, montrant que le modèle n’a pas appris à les traiter — probablement en raison d’un manque de représentativité dans les données d’apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fin du Labo.** Veuillez nettoyer ce notebook en gardant seulement les résultats désirés, l'enregistrer, et le soumettre comme devoir sur Cyberlearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CoursTAL",
   "language": "python",
   "name": "courstal_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
